{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Face Recognition**\n\n**Facial validation System** is a technology capable of matching a human face from a digital image or a video frame against a database of faces, typically employed to authenticate users through ID verification services, works by pinpointing and measuring facial features from a given image. \n\nWe'll be building a face recognition model that uses **Siamese Networks** to give us a distance value that indicates whether 2 images are same or different. \n\n#### **The Dataset**\nWe'll be using the **Extracted Faces** from **face-recognition-dataset**, which is derived from the **LFW Dataset**.\nThe Extracted Faces contains faces extracted from the base images using **Haar-Cascade Face-Detection** (CV2).\n- The dataset contains 1324 different individuals, with 2-50 images per person.\n- But we using even smaller of it as 120 individuals, with 2-50 images per person.\n- The images are of size (128,128,3) and are encoded in RGB.\n- Each folder and image is named with a number, i.e 0.jpg, 1.jpg","metadata":{}},{"cell_type":"markdown","source":"## **Reading the Dataset**\n\nWe're reading the folders and splitting them into **train and test set** for training purposes.","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ntf.__version__, np.__version__","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:13.026166Z","iopub.execute_input":"2022-04-07T14:52:13.026649Z","iopub.status.idle":"2022-04-07T14:52:19.175913Z","shell.execute_reply.started":"2022-04-07T14:52:13.026599Z","shell.execute_reply":"2022-04-07T14:52:19.174622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, f1_score, make_scorer\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import Normalizer, LabelEncoder\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import models\nfrom tensorflow.keras import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:20.621437Z","iopub.execute_input":"2022-04-07T14:52:20.621830Z","iopub.status.idle":"2022-04-07T14:52:20.887198Z","shell.execute_reply.started":"2022-04-07T14:52:20.621795Z","shell.execute_reply":"2022-04-07T14:52:20.886074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Creating clustering** ","metadata":{}},{"cell_type":"code","source":"num_list = random.sample(range(0, 1324), 80)#change to 50 \nprint(num_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:23.350936Z","iopub.execute_input":"2022-04-07T14:52:23.351479Z","iopub.status.idle":"2022-04-07T14:52:23.360305Z","shell.execute_reply.started":"2022-04-07T14:52:23.351425Z","shell.execute_reply":"2022-04-07T14:52:23.358661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(num_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:25.687673Z","iopub.execute_input":"2022-04-07T14:52:25.688114Z","iopub.status.idle":"2022-04-07T14:52:25.695117Z","shell.execute_reply.started":"2022-04-07T14:52:25.688079Z","shell.execute_reply":"2022-04-07T14:52:25.693876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=[]\nX=[]\nfor dirname, _, filenames in os.walk('../input/face-recognition-dataset/Extracted Faces/Extracted Faces'):\n    fc=0\n    ctr = 0\n    for filename in filenames:\n        if ctr<15:\n            if filename!=\"Readme.txt\":\n                b=plt.imread(os.path.join(dirname, filename))\n                try:\n                    b= cv2.cvtColor(b,cv2.COLOR_GRAY2RGB) \n                except:\n                    pass\n                b=cv2.resize(b, (160,160),interpolation = cv2.INTER_AREA)\n\n                if b.shape==(160,160,3) :\n                    if int(dirname.split('/')[-1]) in num_list:\n                        fc = fc+1\n                        #print('Folder',int(dirname.split('/')[-1]),'files',int(filename[0:-4]))\n                        #y.append(int(filename[0:-4]))\n                        y.append(int(dirname.split('/')[-1]))\n                        X.append(b)\n                else:\n                    print('faceshape: ',face.shape)\n        ctr=ctr+1\n    #print(fc,len(y))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:27.433535Z","iopub.execute_input":"2022-04-07T14:52:27.434129Z","iopub.status.idle":"2022-04-07T14:52:52.392444Z","shell.execute_reply.started":"2022-04-07T14:52:27.434070Z","shell.execute_reply":"2022-04-07T14:52:52.391236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fc,len(y))\nprint(len(set(y)))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:52.395298Z","iopub.execute_input":"2022-04-07T14:52:52.396066Z","iopub.status.idle":"2022-04-07T14:52:52.405343Z","shell.execute_reply.started":"2022-04-07T14:52:52.396012Z","shell.execute_reply":"2022-04-07T14:52:52.404048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fc,len(X),len(y))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:52.408344Z","iopub.execute_input":"2022-04-07T14:52:52.408929Z","iopub.status.idle":"2022-04-07T14:52:52.417655Z","shell.execute_reply.started":"2022-04-07T14:52:52.408880Z","shell.execute_reply":"2022-04-07T14:52:52.415971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_cluster = np.array(X)\n\nprint(type(x_cluster))\n\nprint(x_cluster.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:52.420361Z","iopub.execute_input":"2022-04-07T14:52:52.420957Z","iopub.status.idle":"2022-04-07T14:52:52.439936Z","shell.execute_reply.started":"2022-04-07T14:52:52.420907Z","shell.execute_reply":"2022-04-07T14:52:52.438637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Normalization\n# Conversion to float\nx_cluster = x_cluster.astype('float32') \nx_cluster = x_cluster/255.0","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:52.441879Z","iopub.execute_input":"2022-04-07T14:52:52.442407Z","iopub.status.idle":"2022-04-07T14:52:52.505458Z","shell.execute_reply.started":"2022-04-07T14:52:52.442358Z","shell.execute_reply":"2022-04-07T14:52:52.504199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the minimum and maximum values of x_cluster\nprint(x_cluster.min())\nprint(x_cluster.max())","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:52.507122Z","iopub.execute_input":"2022-04-07T14:52:52.507821Z","iopub.status.idle":"2022-04-07T14:52:52.535136Z","shell.execute_reply.started":"2022-04-07T14:52:52.507771Z","shell.execute_reply":"2022-04-07T14:52:52.533696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_cluster = x_cluster.reshape(len(x_cluster),-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:55.924872Z","iopub.execute_input":"2022-04-07T14:52:55.925362Z","iopub.status.idle":"2022-04-07T14:52:55.931388Z","shell.execute_reply.started":"2022-04-07T14:52:55.925317Z","shell.execute_reply":"2022-04-07T14:52:55.929992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_cluster.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:52:57.911598Z","iopub.execute_input":"2022-04-07T14:52:57.912073Z","iopub.status.idle":"2022-04-07T14:52:57.921137Z","shell.execute_reply.started":"2022-04-07T14:52:57.912028Z","shell.execute_reply":"2022-04-07T14:52:57.919479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\n#select different clusters, after analysis 3 is the best for this dataset\ntotal_clusters = 3\n# Initialize the K-Means model\nkmeans = MiniBatchKMeans(n_clusters = total_clusters)\n# Fitting the model to training set\nkmeans.fit(X_cluster)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:00.903427Z","iopub.execute_input":"2022-04-07T14:53:00.903857Z","iopub.status.idle":"2022-04-07T14:53:03.480269Z","shell.execute_reply.started":"2022-04-07T14:53:00.903807Z","shell.execute_reply":"2022-04-07T14:53:03.478807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_index=kmeans.labels_","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:08.549999Z","iopub.execute_input":"2022-04-07T14:53:08.550433Z","iopub.status.idle":"2022-04-07T14:53:08.556213Z","shell.execute_reply.started":"2022-04-07T14:53:08.550396Z","shell.execute_reply":"2022-04-07T14:53:08.554548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(unique, counts) = np.unique(c_index, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nprint(frequencies)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:14.194628Z","iopub.execute_input":"2022-04-07T14:53:14.195087Z","iopub.status.idle":"2022-04-07T14:53:14.203938Z","shell.execute_reply.started":"2022-04-07T14:53:14.195054Z","shell.execute_reply":"2022-04-07T14:53:14.202593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_datag=[]\ny_datag=[]\nfor i in range(0,total_clusters):\n    c_data=[]\n    y_data=[]\n    for j in range(0, len(c_index)):\n        #print(counts[i])\n        if c_index[j] == i: \n            #print (i,j)\n            c_data.append(X[j])\n            y_data.append(y[j])\n    #print(len(c_data),len(y_data))\n    c_datag.append(c_data)\n    y_datag.append(y_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:17.141526Z","iopub.execute_input":"2022-04-07T14:53:17.141965Z","iopub.status.idle":"2022-04-07T14:53:17.151711Z","shell.execute_reply.started":"2022-04-07T14:53:17.141929Z","shell.execute_reply":"2022-04-07T14:53:17.150002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(c_datag[0]), len(c_datag[1]), len(c_datag[2]))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:19.242765Z","iopub.execute_input":"2022-04-07T14:53:19.243226Z","iopub.status.idle":"2022-04-07T14:53:19.251701Z","shell.execute_reply.started":"2022-04-07T14:53:19.243191Z","shell.execute_reply":"2022-04-07T14:53:19.250087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_data=[]\n#for each cluster\nfor k in range(total_clusters):\n    k_data=[]\n    #check if any person belongs to this cluster, if yes, then add\n    for i in num_list:\n        #print(i)\n        person_=[]\n        for u in range(len(c_datag[k])):\n            #print(u,y_datag[k][u],i)\n            if y_datag[k][u]==i:\n                #print(k,i,y_datag[k][u],u)\n                person_.append(c_datag[k][u])\n        k_data.append([person_,i])\n    image_data.append(k_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:21.531620Z","iopub.execute_input":"2022-04-07T14:53:21.532135Z","iopub.status.idle":"2022-04-07T14:53:21.544809Z","shell.execute_reply.started":"2022-04-07T14:53:21.532100Z","shell.execute_reply":"2022-04-07T14:53:21.542965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(image_data[0]), len(image_data[1]),len(image_data[2]))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:24.235387Z","iopub.execute_input":"2022-04-07T14:53:24.235893Z","iopub.status.idle":"2022-04-07T14:53:24.243185Z","shell.execute_reply.started":"2022-04-07T14:53:24.235826Z","shell.execute_reply":"2022-04-07T14:53:24.241653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NPair_X1 = []\nNPair_X2 = []\nPPair_X1 = []\nPPair_X2 = []\nPair_y = []","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:25.909531Z","iopub.execute_input":"2022-04-07T14:53:25.910011Z","iopub.status.idle":"2022-04-07T14:53:25.916347Z","shell.execute_reply.started":"2022-04-07T14:53:25.909976Z","shell.execute_reply":"2022-04-07T14:53:25.914936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_NPairs_samecluster(img_data,cluster_n):\n    for k in range(cluster_n):\n        #print(k)\n        for kk in range(len(img_data[k])):\n            #print(kk)\n            if len(img_data[k][kk][0])>=1 and kk+1<len(img_data[k]):\n                #print(kk+1)\n                if img_data[k][kk][1]!= img_data[k][kk+1][1] and len(img_data[k][kk+1][0])>0:\n                    NPair_X1.append(img_data[k][kk][0][0]) \n                    NPair_X2.append(img_data[k][kk+1][0][0])\n                    Pair_y.append(1)                      ","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:28.307290Z","iopub.execute_input":"2022-04-07T14:53:28.307708Z","iopub.status.idle":"2022-04-07T14:53:28.316496Z","shell.execute_reply.started":"2022-04-07T14:53:28.307672Z","shell.execute_reply":"2022-04-07T14:53:28.314978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_PPairs_diffcluster(img_data,cluster_n):\n    for k in range(cluster_n):\n        for kk in range(len(img_data[k])):\n            if len(img_data[k][kk][0])>=1:\n                if k+1 < cluster_n:\n                    for kkk in range(len(image_data[k+1])):\n                        if img_data[k][kk][1]== img_data[k+1][kkk][1] and len(img_data[k+1][kkk][0])>0:\n                            PPair_X1.append(img_data[k][kk][0][0]) \n                            PPair_X2.append(img_data[k+1][kkk][0][0])\n                            Pair_y.append(0)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:30.838454Z","iopub.execute_input":"2022-04-07T14:53:30.838873Z","iopub.status.idle":"2022-04-07T14:53:30.847499Z","shell.execute_reply.started":"2022-04-07T14:53:30.838820Z","shell.execute_reply":"2022-04-07T14:53:30.846271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_NPairs_samecluster(image_data,3)\nlen(NPair_X1),len(NPair_X2),len(Pair_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:33.441078Z","iopub.execute_input":"2022-04-07T14:53:33.441485Z","iopub.status.idle":"2022-04-07T14:53:33.449493Z","shell.execute_reply.started":"2022-04-07T14:53:33.441451Z","shell.execute_reply":"2022-04-07T14:53:33.448170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(PPair_X1),len(PPair_X2),len(Pair_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:51:17.665949Z","iopub.execute_input":"2022-04-06T13:51:17.666388Z","iopub.status.idle":"2022-04-06T13:51:17.67025Z","shell.execute_reply.started":"2022-04-06T13:51:17.666343Z","shell.execute_reply":"2022-04-06T13:51:17.669135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PPair_X1[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:51:19.761684Z","iopub.execute_input":"2022-04-06T13:51:19.762031Z","iopub.status.idle":"2022-04-06T13:51:19.76609Z","shell.execute_reply.started":"2022-04-06T13:51:19.762Z","shell.execute_reply":"2022-04-06T13:51:19.765197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20, 20))\ncolumns = 5\nrows = 5\nfor i in range(1, columns*rows +1):\n    ax=fig.add_subplot(rows, columns, i)\n    plt.imshow(np.concatenate([NPair_X1[i-1],NPair_X2[i-1]], axis=1))\n    ax.title.set_text(str(Pair_y[i-1])+': negative_pair_same_cluster') \n    ax.set_xticks([]) \n    ax.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:39.138042Z","iopub.execute_input":"2022-04-07T14:53:39.138448Z","iopub.status.idle":"2022-04-07T14:53:41.597272Z","shell.execute_reply.started":"2022-04-07T14:53:39.138412Z","shell.execute_reply":"2022-04-07T14:53:41.595021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_PPairs_diffcluster(image_data,3)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:54.756950Z","iopub.execute_input":"2022-04-07T14:53:54.757370Z","iopub.status.idle":"2022-04-07T14:53:54.764814Z","shell.execute_reply.started":"2022-04-07T14:53:54.757336Z","shell.execute_reply":"2022-04-07T14:53:54.763406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20, 20))\ncolumns = 3\nrows = 6\nfor i in range(1, columns*rows +1):\n    ax=fig.add_subplot(rows, columns, i)\n    plt.imshow(np.concatenate([PPair_X1[i-1],PPair_X2[i-1]], axis=1))\n    ax.title.set_text('0: positive_pair_diff_cluster')\n    ax.set_xticks([])\n    ax.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:53:57.127857Z","iopub.execute_input":"2022-04-07T14:53:57.128299Z","iopub.status.idle":"2022-04-07T14:53:58.964265Z","shell.execute_reply.started":"2022-04-07T14:53:57.128257Z","shell.execute_reply":"2022-04-07T14:53:58.963018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tl=0\ndata=[]\npi=0\nfor i in num_list:\n    pi=pi+1\n    #print('i:',i)\n    person=[]\n    for u in range(0, len(y)):\n        if y[u] == i:\n            person.append(X[u])\n            #print(u)\n    tl=tl+len(person)\n    if len(person)>0:\n        data.append([person, len(person)])\nprint (tl)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:04.952981Z","iopub.execute_input":"2022-04-07T14:54:04.953592Z","iopub.status.idle":"2022-04-07T14:54:04.969052Z","shell.execute_reply.started":"2022-04-07T14:54:04.953533Z","shell.execute_reply":"2022-04-07T14:54:04.967439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = data\n#np.array(k)\n#k.shape\n#print(k)\nprint(k[0][1])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:07.802633Z","iopub.execute_input":"2022-04-07T14:54:07.803111Z","iopub.status.idle":"2022-04-07T14:54:07.809578Z","shell.execute_reply.started":"2022-04-07T14:54:07.803075Z","shell.execute_reply":"2022-04-07T14:54:07.808187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(newX1)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:19.867396Z","iopub.execute_input":"2022-04-07T14:54:19.867817Z","iopub.status.idle":"2022-04-07T14:54:19.872726Z","shell.execute_reply.started":"2022-04-07T14:54:19.867768Z","shell.execute_reply":"2022-04-07T14:54:19.871350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \nrandom.seed(42)\nnewX1=[]\nnewX2=[]\nnewY=[]\nc1 = 0\nc2 = 0\nfor i in range(len(data)):\n    parts=0\n    if data[i][1]>12:\n        parts= int(data[i][1]/3)\n    else:\n        parts= int(data[i][1]/2)\n    #positive sampling from same person\n    for u in range(parts, data[i][1]):\n        g = random.randint(0, parts)\n        if u!=g:\n            newX1.append(data[i][0][u])\n            newX2.append(data[i][0][g])\n            newY.append(0)\n            c1=c1+1\n    #print(k,c1)\n    #negative sampling g from different person\n    for uu in range(len(data)):\n        if uu != i:\n            g = random.randint(0,data[i][1]-1)\n            newX1.append(data[i][0][g])\n            uuu = random.randint(0,data[uu][1]-1)\n            #for uuu in range(int(data[uu][1]/2)):\n                #newX1.append(data[i][0][g])\n            newX2.append(data[uu][0][uuu])\n            newY.append(1)\n            c2=c2+1\nprint(\"Target values count: \"+ str(np.unique(newY, return_counts=True)), c1+c2,c1,c2)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:23.569677Z","iopub.execute_input":"2022-04-07T14:54:23.570200Z","iopub.status.idle":"2022-04-07T14:54:23.609223Z","shell.execute_reply.started":"2022-04-07T14:54:23.570165Z","shell.execute_reply":"2022-04-07T14:54:23.607865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20, 20))\ncolumns = 10\nrows = 10\nfor i in range(1, columns*rows +1):\n    ax=fig.add_subplot(rows, columns, i)\n    plt.imshow(np.concatenate([newX1[i-1],newX2[i-1]], axis=1))\n    ax.title.set_text(str(newY[i-1])) \n    ax.set_xticks([]) \n    ax.set_yticks([])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:29.614505Z","iopub.execute_input":"2022-04-07T14:54:29.614926Z","iopub.status.idle":"2022-04-07T14:54:36.675377Z","shell.execute_reply.started":"2022-04-07T14:54:29.614887Z","shell.execute_reply":"2022-04-07T14:54:36.673594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newX1= newX1 + NPair_X1\nnewX2= newX2 + NPair_X2\nnewX1= newX1 + PPair_X1\nnewX2= newX2 + PPair_X2\nnewY= newY+ Pair_y\nprint(len(newX1),len(newX2),len(newY))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:54:44.635799Z","iopub.execute_input":"2022-04-07T14:54:44.636284Z","iopub.status.idle":"2022-04-07T14:54:44.644895Z","shell.execute_reply.started":"2022-04-07T14:54:44.636247Z","shell.execute_reply":"2022-04-07T14:54:44.643289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = list(zip(newX1, newX2, newY))\n\nrandom.shuffle(c)\n\na, b, y = zip(*c)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:55:21.378491Z","iopub.execute_input":"2022-04-07T14:55:21.378978Z","iopub.status.idle":"2022-04-07T14:55:21.390615Z","shell.execute_reply.started":"2022-04-07T14:55:21.378919Z","shell.execute_reply":"2022-04-07T14:55:21.388902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The minimum and maximum values are 0 and 255 respectively. In the RGB color space the red, green and blue use 8 bits each which have integer values from 0 to 255. So the total number of possible colors is 256256256 = 16777216. Sounds astonishing?","metadata":{}},{"cell_type":"code","source":"Xpca=np.array(a)\nXpca.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:55:24.492358Z","iopub.execute_input":"2022-04-07T14:55:24.492762Z","iopub.status.idle":"2022-04-07T14:55:24.607225Z","shell.execute_reply.started":"2022-04-07T14:55:24.492727Z","shell.execute_reply":"2022-04-07T14:55:24.605903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = models.load_model('../input/karasfacenet/facenet_keras/facenet_keras.h5')\n\nbase_model.load_weights(\"../input/karasfacenet/facenet_keras_weights/facenet_keras_weights.h5\")\nbase_model.trainable=False\noutput1=base_model.predict(np.array(a)/255)\noutput2=base_model.predict(np.array(b)/255)\nindexes1=[i for i,x in enumerate(y) if x == 1]\nindexes0=[i for i,x in enumerate(y) if x == 0]","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:55:26.952826Z","iopub.execute_input":"2022-04-07T14:55:26.953302Z","iopub.status.idle":"2022-04-07T14:55:58.213370Z","shell.execute_reply.started":"2022-04-07T14:55:26.953266Z","shell.execute_reply":"2022-04-07T14:55:58.211762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=Model(base_model.input, base_model.output)\nimport tensorflow.keras.backend as K\nimport tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:03.521117Z","iopub.execute_input":"2022-04-07T14:56:03.521542Z","iopub.status.idle":"2022-04-07T14:56:03.560438Z","shell.execute_reply.started":"2022-04-07T14:56:03.521503Z","shell.execute_reply":"2022-04-07T14:56:03.559244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v=Input((160,160,3))\np=Input((160,160,3))\n\nfeaturesA=features(v)\nfeaturesB=features(p)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:08.382503Z","iopub.execute_input":"2022-04-07T14:56:08.382947Z","iopub.status.idle":"2022-04-07T14:56:10.524207Z","shell.execute_reply.started":"2022-04-07T14:56:08.382911Z","shell.execute_reply":"2022-04-07T14:56:10.522961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\ndistance = L1_layer([featuresA, featuresB])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:12.587394Z","iopub.execute_input":"2022-04-07T14:56:12.587818Z","iopub.status.idle":"2022-04-07T14:56:12.600174Z","shell.execute_reply.started":"2022-04-07T14:56:12.587782Z","shell.execute_reply":"2022-04-07T14:56:12.598953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:16.259536Z","iopub.execute_input":"2022-04-07T14:56:16.259966Z","iopub.status.idle":"2022-04-07T14:56:16.300613Z","shell.execute_reply.started":"2022-04-07T14:56:16.259927Z","shell.execute_reply":"2022-04-07T14:56:16.299383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=[v,p],outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:19.220213Z","iopub.execute_input":"2022-04-07T14:56:19.220618Z","iopub.status.idle":"2022-04-07T14:56:19.232465Z","shell.execute_reply.started":"2022-04-07T14:56:19.220583Z","shell.execute_reply":"2022-04-07T14:56:19.231235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_=[]\nfor i in range(len(a)):\n    connect_a_b =[]\n    connect_a_b.append(a[i])\n    connect_a_b.append(b[i])\n    x_.append(connect_a_b)\n    \nx_train,x_test,y_train,y_test=train_test_split(x_,y,test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:21.507295Z","iopub.execute_input":"2022-04-07T14:56:21.507714Z","iopub.status.idle":"2022-04-07T14:56:21.522959Z","shell.execute_reply.started":"2022-04-07T14:56:21.507677Z","shell.execute_reply":"2022-04-07T14:56:21.521693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_a=[]\nx_train_b=[]\nx_test_a = []\nx_test_b = []\nfor ob in x_train:\n    x_train_a.append(ob[0])\n    x_train_b.append(ob[1])\nfor ob in x_test:\n    x_test_a.append(ob[0])\n    x_test_b.append(ob[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:24.147431Z","iopub.execute_input":"2022-04-07T14:56:24.147902Z","iopub.status.idle":"2022-04-07T14:56:24.156821Z","shell.execute_reply.started":"2022-04-07T14:56:24.147838Z","shell.execute_reply":"2022-04-07T14:56:24.155070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_clu_a = x_test_a\nx_test_clu_b = x_test_b\ny_test_clu = y_test","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:26.548386Z","iopub.execute_input":"2022-04-07T14:56:26.548836Z","iopub.status.idle":"2022-04-07T14:56:26.556348Z","shell.execute_reply.started":"2022-04-07T14:56:26.548801Z","shell.execute_reply":"2022-04-07T14:56:26.553955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()\nhistory=model.fit([np.array(x_train_a)/255, np.array(x_train_b)/255],np.array(y_train),validation_data=([np.array(x_test_a)/255, np.array(x_test_b)/255],np.array(y_test)),epochs=20, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:56:32.044780Z","iopub.execute_input":"2022-04-07T14:56:32.045283Z","iopub.status.idle":"2022-04-07T15:00:13.971894Z","shell.execute_reply.started":"2022-04-07T14:56:32.045249Z","shell.execute_reply":"2022-04-07T15:00:13.970513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Overfitting analysis\")\naxs[0].plot(list(range(1,21)), history.history['val_accuracy'], list(range(1,21)), history.history['accuracy'])\n\naxs[0].title.set_text(\"Accuracy\")\naxs[0].legend([\"validation accuracy\", \"training accuracy\"])\naxs[1].plot(list(range(1,21)), history.history['val_loss'], list(range(1,21)), history.history['loss'])\naxs[1].title.set_text('Loss')\naxs[1].legend([\"validation loss\", \"trainig loss\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:00:18.340265Z","iopub.execute_input":"2022-04-07T15:00:18.340711Z","iopub.status.idle":"2022-04-07T15:00:18.802667Z","shell.execute_reply.started":"2022-04-07T15:00:18.340675Z","shell.execute_reply":"2022-04-07T15:00:18.801279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# end ---- Dividing the images based on the clusters","metadata":{}},{"cell_type":"markdown","source":"# Without clustering process test 1","metadata":{}},{"cell_type":"code","source":"y=[]\nX=[]\nfc=0\nfor dirname, _, filenames in os.walk('../input/face-recognition-dataset/Extracted Faces/Extracted Faces'):\n    #fc=fc+1\n    #print (fc)\n    ctr = 0\n    for filename in filenames:\n        if ctr<15:#fc=fc+1\n            if filename!=\"Readme.txt\":\n                #fc=fc+1\n                b=plt.imread(os.path.join(dirname, filename))\n                try:\n                    b= cv2.cvtColor(b,cv2.COLOR_GRAY2RGB) \n                except:\n                    #print('exception')\n                    pass\n                b=cv2.resize(b, (160,160),interpolation = cv2.INTER_AREA)\n                if b.shape==(160,160,3) :\n                    #fc=fc+1\n                    if int(dirname.split('/')[-1]) in num_list:\n                        #fc=fc+1\n                        #print(dirname.split('/')[-1], filename, filenames)\n                        #print('Folder',int(dirname.split('/')[-1]),'files',int(filename[0:-4]))\n                        #y.append(int(filename[0:-4]))\n                        y.append(int(dirname.split('/')[-1]))\n                        X.append(b)\n            else:\n                print('faceshape: ',face.shape)\n        ctr=ctr+1\nprint(fc,len(y))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:35:34.718759Z","iopub.execute_input":"2022-04-07T14:35:34.719159Z","iopub.status.idle":"2022-04-07T14:36:14.930497Z","shell.execute_reply.started":"2022-04-07T14:35:34.719127Z","shell.execute_reply":"2022-04-07T14:36:14.928412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(y))\nprint(len(set(y)))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:36:21.382051Z","iopub.execute_input":"2022-04-07T14:36:21.382548Z","iopub.status.idle":"2022-04-07T14:36:21.391208Z","shell.execute_reply.started":"2022-04-07T14:36:21.382506Z","shell.execute_reply":"2022-04-07T14:36:21.389841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:36:24.276119Z","iopub.execute_input":"2022-04-07T14:36:24.276549Z","iopub.status.idle":"2022-04-07T14:36:24.282975Z","shell.execute_reply.started":"2022-04-07T14:36:24.276516Z","shell.execute_reply":"2022-04-07T14:36:24.281560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tl=0\ndata=[]\npi=0\nfor i in num_list:\n    pi=pi+1\n    #print('i:',i)\n    person=[]\n    for u in range(0, len(y)):\n        if y[u] == i:\n            person.append(X[u])\n    #print(person)\n    tl=tl+len(person)\n    if len(person)>0:\n        data.append([person, len(person)])\nprint (tl)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:36:26.779233Z","iopub.execute_input":"2022-04-07T14:36:26.779618Z","iopub.status.idle":"2022-04-07T14:36:26.791469Z","shell.execute_reply.started":"2022-04-07T14:36:26.779588Z","shell.execute_reply":"2022-04-07T14:36:26.790038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:36:30.044567Z","iopub.execute_input":"2022-04-07T14:36:30.044963Z","iopub.status.idle":"2022-04-07T14:36:30.052050Z","shell.execute_reply.started":"2022-04-07T14:36:30.044907Z","shell.execute_reply":"2022-04-07T14:36:30.050808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random \nrandom.seed(42)\nnewX1=[]\nnewX2=[]\nnewY=[]\nc1 = 0\nc2 = 0\nfor i in range(len(data)):\n    parts=0\n    if data[i][1]>12:\n        parts= int(data[i][1]/3)\n    else:\n        parts= int(data[i][1]/2)\n    #positive sampling from same person\n    for u in range(parts, data[i][1]):\n        g = random.randint(0, parts)\n        if u!=g:\n            newX1.append(data[i][0][u])\n            newX2.append(data[i][0][g])\n            newY.append(0)\n            c1=c1+1\n    #print(k,c1)\n    #negative sampling g from different person\n    for uu in range(len(data)):\n        if uu != i:\n            g = random.randint(0,data[i][1]-1)\n            newX1.append(data[i][0][g])\n            uuu = random.randint(0,data[uu][1]-1)\n            #for uuu in range(int(data[uu][1]/2)):\n                #newX1.append(data[i][0][g])\n            newX2.append(data[uu][0][uuu])\n            newY.append(1)\n            c2=c2+1\nprint(\"Target values count: \"+ str(np.unique(newY, return_counts=True)), c1+c2,c1,c2)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:13.726630Z","iopub.execute_input":"2022-04-07T14:38:13.727094Z","iopub.status.idle":"2022-04-07T14:38:13.769094Z","shell.execute_reply.started":"2022-04-07T14:38:13.727061Z","shell.execute_reply":"2022-04-07T14:38:13.767460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 15))\ncolumns = 10\nrows = 12\nfor i in range(1, columns*rows +1):\n    ax=fig.add_subplot(rows, columns, i)\n    \n    plt.imshow(np.concatenate([newX1[i-1],newX2[i-1]], axis=1))\n    ax.title.set_text(newY[i-1])\n    ax.set_xticks([])\n    ax.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:17.034936Z","iopub.execute_input":"2022-04-07T14:38:17.035365Z","iopub.status.idle":"2022-04-07T14:38:24.391370Z","shell.execute_reply.started":"2022-04-07T14:38:17.035334Z","shell.execute_reply":"2022-04-07T14:38:24.389037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = list(zip(newX1, newX2, newY))\n\nrandom.shuffle(c)\n\na, b, y = zip(*c)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:34.368474Z","iopub.execute_input":"2022-04-07T14:38:34.368967Z","iopub.status.idle":"2022-04-07T14:38:34.381556Z","shell.execute_reply.started":"2022-04-07T14:38:34.368931Z","shell.execute_reply":"2022-04-07T14:38:34.380095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.array(a)\nXpca=np.array(a)\nXpca.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:37.815704Z","iopub.execute_input":"2022-04-07T14:38:37.816308Z","iopub.status.idle":"2022-04-07T14:38:37.952188Z","shell.execute_reply.started":"2022-04-07T14:38:37.816270Z","shell.execute_reply":"2022-04-07T14:38:37.950954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xpca=Xpca.reshape(Xpca.shape[0],Xpca.shape[1]*Xpca.shape[2]*Xpca.shape[3])\nfrom sklearn.decomposition import PCA\n\nfaces_pca = PCA(n_components=0.9)\nfaces_pca.fit(Xpca)\nfig, axes = plt.subplots(2,5,figsize=(9,3),\n subplot_kw={'xticks':[], 'yticks':[]},\n gridspec_kw=dict(hspace=0.01, wspace=0.01))\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(np.interp(faces_pca.components_[i], (min(faces_pca.components_[i]),max(faces_pca.components_[i])), (0, 255)).reshape(160,160,3).astype(\"int\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:32:36.62837Z","iopub.execute_input":"2022-01-25T08:32:36.628747Z","iopub.status.idle":"2022-01-25T08:36:14.442089Z","shell.execute_reply.started":"2022-01-25T08:32:36.628714Z","shell.execute_reply":"2022-01-25T08:36:14.441196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xpca.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:41.503666Z","iopub.execute_input":"2022-04-07T14:38:41.504164Z","iopub.status.idle":"2022-04-07T14:38:41.512294Z","shell.execute_reply.started":"2022-04-07T14:38:41.504131Z","shell.execute_reply":"2022-04-07T14:38:41.510681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = models.load_model('../input/karasfacenet/facenet_keras/facenet_keras.h5')\n\nbase_model.load_weights(\"../input/karasfacenet/facenet_keras_weights/facenet_keras_weights.h5\")\nbase_model.trainable=False\noutput1=base_model.predict(np.array(a)/255)\noutput2=base_model.predict(np.array(b)/255)\nindexes1=[i for i,x in enumerate(y) if x == 1]\nindexes0=[i for i,x in enumerate(y) if x == 0]","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:38:45.047438Z","iopub.execute_input":"2022-04-07T14:38:45.047821Z","iopub.status.idle":"2022-04-07T14:39:19.211238Z","shell.execute_reply.started":"2022-04-07T14:38:45.047782Z","shell.execute_reply":"2022-04-07T14:39:19.209738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#c = list(zip(newX1, newX2, newY))\n\n#random.shuffle(c)\n\n#a, b, y = zip(*c)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T08:37:09.349895Z","iopub.execute_input":"2022-01-25T08:37:09.350238Z","iopub.status.idle":"2022-01-25T08:37:09.399736Z","shell.execute_reply.started":"2022-01-25T08:37:09.350205Z","shell.execute_reply":"2022-01-25T08:37:09.398944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:23.366397Z","iopub.execute_input":"2022-04-07T14:39:23.366868Z","iopub.status.idle":"2022-04-07T14:39:23.372876Z","shell.execute_reply.started":"2022-04-07T14:39:23.366808Z","shell.execute_reply":"2022-04-07T14:39:23.371265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=Model(base_model.input, base_model.output)\nimport tensorflow.keras.backend as K\nimport tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:26.370022Z","iopub.execute_input":"2022-04-07T14:39:26.370430Z","iopub.status.idle":"2022-04-07T14:39:26.410130Z","shell.execute_reply.started":"2022-04-07T14:39:26.370398Z","shell.execute_reply":"2022-04-07T14:39:26.408717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v=Input((160,160,3))\np=Input((160,160,3))\n\nfeaturesA=features(v)\nfeaturesB=features(p)\ndistance= Lambda(distance)([featuresA,featuresB])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:28.410402Z","iopub.execute_input":"2022-04-07T14:39:28.410830Z","iopub.status.idle":"2022-04-07T14:39:30.478250Z","shell.execute_reply.started":"2022-04-07T14:39:28.410799Z","shell.execute_reply":"2022-04-07T14:39:30.477145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def distance(vecs):\n    x, y = vecs\n    x = K.l2_normalize(x, axis=-1)\n    y = K.l2_normalize(y, axis=-1)\n    \n    return K.abs(x-y)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:31.658522Z","iopub.execute_input":"2022-04-07T14:39:31.658908Z","iopub.status.idle":"2022-04-07T14:39:31.667948Z","shell.execute_reply.started":"2022-04-07T14:39:31.658865Z","shell.execute_reply":"2022-04-07T14:39:31.666696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v=Input((160,160,3))\np=Input((160,160,3))\n\nfeaturesA=features(v)\nfeaturesB=features(p)\ndistance= Lambda(distance)([featuresA,featuresB])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:33.373100Z","iopub.execute_input":"2022-04-07T14:39:33.373622Z","iopub.status.idle":"2022-04-07T14:39:35.418549Z","shell.execute_reply.started":"2022-04-07T14:39:33.373572Z","shell.execute_reply":"2022-04-07T14:39:35.417375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x= Dense(96, activation=\"relu\")(distance)\nx= Dropout(0.3)(x)\nx= Dense(64)(x)\noutputs = Dense(1, activation=\"sigmoid\")(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:36.387629Z","iopub.execute_input":"2022-04-07T14:39:36.388031Z","iopub.status.idle":"2022-04-07T14:39:36.427050Z","shell.execute_reply.started":"2022-04-07T14:39:36.387998Z","shell.execute_reply":"2022-04-07T14:39:36.425774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=[v,p],outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:38.209971Z","iopub.execute_input":"2022-04-07T14:39:38.210392Z","iopub.status.idle":"2022-04-07T14:39:38.222050Z","shell.execute_reply.started":"2022-04-07T14:39:38.210354Z","shell.execute_reply":"2022-04-07T14:39:38.220789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_=[]\nfor i in range(len(a)):\n    connect_a_b =[]\n    connect_a_b.append(a[i])\n    connect_a_b.append(b[i])\n    x_.append(connect_a_b)\n    \nx_train,x_test,y_train,y_test=train_test_split(x_,y,test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:39.977931Z","iopub.execute_input":"2022-04-07T14:39:39.978387Z","iopub.status.idle":"2022-04-07T14:39:39.995830Z","shell.execute_reply.started":"2022-04-07T14:39:39.978348Z","shell.execute_reply":"2022-04-07T14:39:39.994372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('training size: ', len(x_train), 'testing size: ', len(x_test))","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:43.494582Z","iopub.execute_input":"2022-04-07T14:39:43.494976Z","iopub.status.idle":"2022-04-07T14:39:43.502523Z","shell.execute_reply.started":"2022-04-07T14:39:43.494928Z","shell.execute_reply":"2022-04-07T14:39:43.501034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_a=[]\nx_train_b=[]\nx_test_a = []\nx_test_b = []\nfor ob in x_train:\n    x_train_a.append(ob[0])\n    x_train_b.append(ob[1])\nfor ob in x_test:\n    x_test_a.append(ob[0])\n    x_test_b.append(ob[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:48.305851Z","iopub.execute_input":"2022-04-07T14:39:48.306311Z","iopub.status.idle":"2022-04-07T14:39:48.315461Z","shell.execute_reply.started":"2022-04-07T14:39:48.306278Z","shell.execute_reply":"2022-04-07T14:39:48.313828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_s_a=x_test_a\nx_test_s_b=x_test_b\ny_test_s = y_test","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:39:51.304106Z","iopub.execute_input":"2022-04-07T14:39:51.304502Z","iopub.status.idle":"2022-04-07T14:39:51.310196Z","shell.execute_reply.started":"2022-04-07T14:39:51.304471Z","shell.execute_reply":"2022-04-07T14:39:51.308617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\nmodel.summary()\n#history=model.fit([np.array(a)[:120]/255, np.array(b)[:120]/255],np.array(y)[:120],validation_data=([np.array(a)[120:]/255, np.array(b)[120:]/255],np.array(y)[120:]), epochs=10, batch_size=16)\nhistory=model.fit([np.array(x_train_a)/255, np.array(x_train_b)/255],np.array(y_train),validation_data=([np.array(x_test_a)/255, np.array(x_test_b)/255],np.array(y_test)),epochs=20, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:40:59.631762Z","iopub.execute_input":"2022-04-07T14:40:59.632485Z","iopub.status.idle":"2022-04-07T14:45:07.725620Z","shell.execute_reply.started":"2022-04-07T14:40:59.632448Z","shell.execute_reply":"2022-04-07T14:45:07.724453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2)\nfig.set_size_inches(18, 4)\nfig.suptitle(\"Overfitting analysis\")\naxs[0].plot(list(range(1,21)), history.history['val_accuracy'], list(range(1,21)), history.history['accuracy'])\n\naxs[0].title.set_text(\"Accuracy\")\naxs[0].legend([\"validation accuracy\", \"training accuracy\"])\naxs[1].plot(list(range(1,21)), history.history['val_loss'], list(range(1,21)), history.history['loss'])\naxs[1].title.set_text('Loss')\naxs[1].legend([\"validation loss\", \"trainig loss\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T14:45:20.417176Z","iopub.execute_input":"2022-04-07T14:45:20.417611Z","iopub.status.idle":"2022-04-07T14:45:20.880143Z","shell.execute_reply.started":"2022-04-07T14:45:20.417576Z","shell.execute_reply":"2022-04-07T14:45:20.878944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Without clustering Creating Triplets\n\nWe use the train and test list to create triplets of **(anchor, postive, negative)** face data, where positive is the same person and negative is a different person than anchor.","metadata":{}},{"cell_type":"code","source":"# Setting random seeds to enable consistency while testing.\nrandom.seed(5)\nnp.random.seed(5)\ntf.random.set_seed(5)\n\nROOT = \"../input/face-recognition-dataset/Extracted Faces/Extracted Faces\"\n\ndef read_image(index):\n    path = os.path.join(ROOT, index[0], index[1])\n    #print(index[0],index[1])\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:43:18.876185Z","iopub.execute_input":"2022-01-24T10:43:18.876824Z","iopub.status.idle":"2022-01-24T10:43:19.012552Z","shell.execute_reply.started":"2022-01-24T10:43:18.876694Z","shell.execute_reply":"2022-01-24T10:43:19.010994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset(directory, split=0.98):\n    print(directory)\n    folders = os.listdir(directory)\n    #print(folders)\n    num_train = int(len(folders)*split)\n    \n    random.shuffle(folders)\n    \n    train_list, test_list = {}, {}\n    \n    # Creating Train-list\n    for folder in folders:\n        if int(folder) in num_list:\n            num_files = len(os.listdir(os.path.join(directory, folder)))\n            train_list[folder] = num_files\n    \n    # Creating Test-list\n    for folder in folders[num_train:]:\n        num_files = len(os.listdir(os.path.join(directory, folder)))\n        test_list[folder] = num_files  \n    \n    return train_list, test_list\n\ntrain_list, test_list = split_dataset(ROOT, split=0.9)\nprint(\"Length of training list:\", len(train_list))\nprint(\"Length of testing list :\", len(test_list))\n\n# train_list, test list contains the folder names along with the number of files in the folder.\nprint(\"\\nTest List:\", test_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:50:43.570208Z","iopub.execute_input":"2022-01-21T16:50:43.570548Z","iopub.status.idle":"2022-01-21T16:50:43.751211Z","shell.execute_reply.started":"2022-01-21T16:50:43.570517Z","shell.execute_reply":"2022-01-21T16:50:43.750105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_triplets(directory, folder_list, max_files=10):\n    triplets = []\n    folders = list(folder_list.keys())\n    \n    for folder in folders:\n        path = os.path.join(directory, folder)\n        files = list(os.listdir(path))[:max_files]\n        num_files = len(files)\n        \n        for i in range(num_files-1):\n            for j in range(i+1, num_files):\n                anchor = (folder, f\"{i}.jpg\")\n                positive = (folder, f\"{j}.jpg\")\n\n                neg_folder = folder\n                while neg_folder == folder:\n                    neg_folder = random.choice(folders)\n                neg_file = random.randint(0, folder_list[neg_folder]-1)\n                negative = (neg_folder, f\"{neg_file}.jpg\")\n\n                triplets.append((anchor, positive, negative))\n            \n    random.shuffle(triplets)\n    return triplets","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:51:26.793742Z","iopub.execute_input":"2022-01-21T16:51:26.794081Z","iopub.status.idle":"2022-01-21T16:51:26.802151Z","shell.execute_reply.started":"2022-01-21T16:51:26.794049Z","shell.execute_reply":"2022-01-21T16:51:26.801273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_triplet = create_triplets(ROOT, train_list)\ntest_triplet  = create_triplets(ROOT, test_list)\n\nprint(\"Number of training triplets:\", len(train_triplet))\nprint(\"Number of testing triplets :\", len(test_triplet))\n\nprint(\"\\nExamples of triplets:\")\nfor i in range(5):\n    print(train_triplet[i])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:51:29.884156Z","iopub.execute_input":"2022-01-21T16:51:29.88449Z","iopub.status.idle":"2022-01-21T16:51:30.018983Z","shell.execute_reply.started":"2022-01-21T16:51:29.884458Z","shell.execute_reply":"2022-01-21T16:51:30.018083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Batch-Generator\n\nCreating a **Batch-Generator** that converts the triplets passed into batches of face-data and **preproccesses** it before returning the data into seperate lists.\n\n**Parameters:**\n- Batch_size: Batch_size of the data to return\n- Preprocess: Whether to preprocess the data or not","metadata":{}},{"cell_type":"code","source":"def get_batch(triplet_list, batch_size=256, preprocess=True):\n    batch_steps = len(triplet_list)//batch_size\n    \n    for i in range(batch_steps+1):\n        anchor   = []\n        positive = []\n        negative = []\n        \n        j = i*batch_size\n        while j<(i+1)*batch_size and j<len(triplet_list):\n            a, p, n = triplet_list[j]\n            anchor.append(read_image(a))\n            positive.append(read_image(p))\n            negative.append(read_image(n))\n            j+=1\n            \n        anchor = np.array(anchor)\n        positive = np.array(positive)\n        negative = np.array(negative)\n        \n        if preprocess:\n            anchor = preprocess_input(anchor)\n            positive = preprocess_input(positive)\n            negative = preprocess_input(negative)\n        \n        yield ([anchor, positive, negative])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:51:34.504143Z","iopub.execute_input":"2022-01-21T16:51:34.504492Z","iopub.status.idle":"2022-01-21T16:51:34.512706Z","shell.execute_reply.started":"2022-01-21T16:51:34.504459Z","shell.execute_reply":"2022-01-21T16:51:34.511633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the Data\n\nPlotting the data generated from **get_batch()** to see the results","metadata":{}},{"cell_type":"code","source":"num_plots = 6\n\nf, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n\nfor x in get_batch(train_triplet, batch_size=num_plots, preprocess=False):\n    a,p,n = x\n    for i in range(num_plots):\n        axes[i, 0].imshow(a[i])\n        axes[i, 1].imshow(p[i])\n        axes[i, 2].imshow(n[i])\n        i+=1\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:51:38.087892Z","iopub.execute_input":"2022-01-21T16:51:38.088229Z","iopub.status.idle":"2022-01-21T16:51:40.431501Z","shell.execute_reply.started":"2022-01-21T16:51:38.088198Z","shell.execute_reply":"2022-01-21T16:51:40.43046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Creating the Model**\n\nUnlike a conventional CNN, the **Siamese Network** does not classify the images into certain categories or labels, rather it only finds out the distance between any two given images. If the images have the same label, then the network should learn the parameters, i.e. the weights and the biases in such a way that it should produce a smaller distance between the two images, and if they belong to different labels, then the distance should be larger\n\n![Siamese Network Image](https://miro.medium.com/max/2000/1*05hUCDHhnl4hdjqvdVTHtw.png)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend, layers, metrics\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Model, Sequential\n\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:51:50.15378Z","iopub.execute_input":"2022-01-21T16:51:50.154117Z","iopub.status.idle":"2022-01-21T16:51:50.158937Z","shell.execute_reply.started":"2022-01-21T16:51:50.154084Z","shell.execute_reply":"2022-01-21T16:51:50.157947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoder\n\nThe **Encoder** is responsible for converting the passed images into their feature vectors. We're using a pretrained model, **Xception model** which is based on **Inception_V3 model.** By using transfer learning, we can significantly reduce the training time and size of the dataset.\n\nThe Model is connected to **Fully Connected (Dense)** layers and the last layer normalises the data using **L2 Normalisation**. *(L2 Normalisation is a technique that modifies the dataset values in a way that in each row the sum of the squares will always be up to 1)*","metadata":{}},{"cell_type":"code","source":"def get_encoder(input_shape):\n    \"\"\" Returns the image encoding model \"\"\"\n\n    pretrained_model = Xception(\n        input_shape=input_shape,\n        weights='imagenet',\n        include_top=False,\n        pooling='avg',\n    )\n    \n    for i in range(len(pretrained_model.layers)-27):\n        pretrained_model.layers[i].trainable = False\n\n    encode_model = Sequential([\n        pretrained_model,\n        layers.Flatten(),\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n    ], name=\"Encode_Model\")\n    return encode_model","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:08.490176Z","iopub.execute_input":"2022-01-21T16:52:08.490514Z","iopub.status.idle":"2022-01-21T16:52:08.496885Z","shell.execute_reply.started":"2022-01-21T16:52:08.490481Z","shell.execute_reply":"2022-01-21T16:52:08.495805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Siamese Network\n\nWe're creating a **Siamese Network** that takes 3 input images, (anchor, postive, negative) and uses the encoder above to encode the images to their feature vectors. Those features are passed to a distance layer which computes the distance between **(anchor, positive)** and **(anchor, negative)** pairs.\n\nWe'll be defining a custom layer to compute the distance.\n\n**Distance Formula**:\n\n![image.png](attachment:5e83389c-697d-4b02-8b39-81f5eba0ba9e.png)","metadata":{},"attachments":{"5e83389c-697d-4b02-8b39-81f5eba0ba9e.png":{"image/png":"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"}}},{"cell_type":"code","source":"class DistanceLayer(layers.Layer):\n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def call(self, anchor, positive, negative):\n        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n        return (ap_distance, an_distance)\n    \n\ndef get_siamese_network(input_shape = (128, 128, 3)):\n    encoder = get_encoder(input_shape)\n    \n    # Input Layers for the images\n    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n    \n    ## Generate the encodings (feature vectors) for the images\n    encoded_a = encoder(anchor_input)\n    encoded_p = encoder(positive_input)\n    encoded_n = encoder(negative_input)\n    \n    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n    distances = DistanceLayer()(\n        encoder(anchor_input),\n        encoder(positive_input),\n        encoder(negative_input)\n    )\n    \n    # Creating the Model\n    siamese_network = Model(\n        inputs  = [anchor_input, positive_input, negative_input],\n        outputs = distances,\n        name = \"Siamese_Network\"\n    )\n    return siamese_network\n\nsiamese_network = get_siamese_network()\nsiamese_network.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:11.825953Z","iopub.execute_input":"2022-01-21T16:52:11.826442Z","iopub.status.idle":"2022-01-21T16:52:16.68656Z","shell.execute_reply.started":"2022-01-21T16:52:11.826399Z","shell.execute_reply":"2022-01-21T16:52:16.685062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(siamese_network, show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:47.319788Z","iopub.execute_input":"2022-01-21T16:52:47.320131Z","iopub.status.idle":"2022-01-21T16:52:47.808386Z","shell.execute_reply.started":"2022-01-21T16:52:47.320099Z","shell.execute_reply":"2022-01-21T16:52:47.807303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Putting everything together\n\nWe now need to implement a model with custom training loop and loss function so we can compute the **triplet loss** using the three embeddings produced by the Siamese network.\n\nWe'll create a **Mean metric** instance to track the loss of the training process.\n\n**Triplet Loss Function:**\n\n<img src=\"https://miro.medium.com/max/1838/0*AX2TSZNk19_gDgTN.png\" alt=\"Loss Formula\" width=\"400\"/>","metadata":{}},{"cell_type":"code","source":"class SiameseModel(Model):\n    # Builds a Siamese model based on a base-model\n    def __init__(self, siamese_network, margin=1.0):\n        super(SiameseModel, self).__init__()\n        \n        self.margin = margin\n        self.siamese_network = siamese_network\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n\n    def call(self, inputs):\n        return self.siamese_network(inputs)\n\n    def train_step(self, data):\n        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n        with tf.GradientTape() as tape:\n            loss = self._compute_loss(data)\n            \n        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self._compute_loss(data)\n        \n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def _compute_loss(self, data):\n        # Get the two distances from the network, then compute the triplet loss\n        ap_distance, an_distance = self.siamese_network(data)\n        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n        return loss\n\n    @property\n    def metrics(self):\n        # We need to list our metrics so the reset_states() can be called automatically.\n        return [self.loss_tracker]","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:51.432489Z","iopub.execute_input":"2022-01-21T16:52:51.432837Z","iopub.status.idle":"2022-01-21T16:52:51.442821Z","shell.execute_reply.started":"2022-01-21T16:52:51.432804Z","shell.execute_reply":"2022-01-21T16:52:51.441813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_model = SiameseModel(siamese_network)\n\noptimizer = Adam(learning_rate=1e-3, epsilon=1e-01)\nsiamese_model.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:54.488138Z","iopub.execute_input":"2022-01-21T16:52:54.488495Z","iopub.status.idle":"2022-01-21T16:52:54.516336Z","shell.execute_reply.started":"2022-01-21T16:52:54.48846Z","shell.execute_reply":"2022-01-21T16:52:54.515591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Training the Model**\n\nWe'll now be training the siamese_model on batches of triplets. We'll print the training loss, along with additional metrics from testing every epoch. The model weights will also be saved whenever it outperforms the previous max_accuracy.\n\nWe're hoping to collect more metrics about the model to evaluate how to increase the accuracy of the model. The epochs have been set to avoid going over Kaggle's time constraint.\n\n### Test Function\n\n**test_on_triplets()** function will be responsible for testing the model on test_triplets. It'll collect metrics **(accuracy, means, stds)** by predicting on the train data. We'll also be printing the Accuracy of the model after testing.","metadata":{}},{"cell_type":"code","source":"def test_on_triplets(batch_size = 256):\n    pos_scores, neg_scores = [], []\n\n    for data in get_batch(test_triplet, batch_size=batch_size):\n        prediction = siamese_model.predict(data)\n        pos_scores += list(prediction[0])\n        neg_scores += list(prediction[1])\n    \n    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n    ap_mean = np.mean(pos_scores)\n    an_mean = np.mean(neg_scores)\n    ap_stds = np.std(pos_scores)\n    an_stds = np.std(neg_scores)\n    \n    print(f\"Accuracy on test = {accuracy:.5f}\")\n    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:52:57.602023Z","iopub.execute_input":"2022-01-21T16:52:57.602379Z","iopub.status.idle":"2022-01-21T16:52:57.609096Z","shell.execute_reply.started":"2022-01-21T16:52:57.602331Z","shell.execute_reply":"2022-01-21T16:52:57.608225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_all = False\nepochs = 20\nbatch_size = 128\n\nmax_acc = 0\ntrain_loss = []\ntest_metrics = []\n\nfor epoch in range(1, epochs+1):\n    t = time.time()\n    \n    # Training the model on train data\n    epoch_loss = []\n    for data in get_batch(train_triplet, batch_size=batch_size):\n        loss = siamese_model.train_on_batch(data)\n        epoch_loss.append(loss)\n    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n    train_loss.append(epoch_loss)\n\n    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n    print(f\"Loss on train    = {epoch_loss:.5f}\")\n    \n    # Testing the model on test data\n    metric = test_on_triplets(batch_size=batch_size)\n    test_metrics.append(metric)\n    accuracy = metric[0]\n    \n    # Saving the model weights\n    if save_all or accuracy>=max_acc:\n        siamese_model.save_weights(\"siamese_model\")\n        max_acc = accuracy\n\n# Saving the model after all epochs run\nsiamese_model.save_weights(\"siamese_model-final\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:00:28.023187Z","iopub.execute_input":"2022-01-21T17:00:28.023548Z","iopub.status.idle":"2022-01-21T17:07:02.73712Z","shell.execute_reply.started":"2022-01-21T17:00:28.023514Z","shell.execute_reply":"2022-01-21T17:07:02.736263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Evaluating the Model**\n","metadata":{}},{"cell_type":"code","source":"def plot_metrics(loss, metrics):\n    # Extracting individual metrics from metrics\n    accuracy = metrics[:, 0]\n    ap_mean  = metrics[:, 1]\n    an_mean  = metrics[:, 2]\n    ap_stds  = metrics[:, 3]\n    an_stds  = metrics[:, 4]\n    \n    plt.figure(figsize=(15,5))\n    \n    # Plotting the loss over epochs\n    plt.subplot(121)\n    plt.plot(loss, 'b', label='Loss')\n    plt.title('Training loss')\n    plt.legend()\n    \n    # Plotting the accuracy over epochs\n    plt.subplot(122)\n    plt.plot(accuracy, 'r', label='Accuracy')\n    plt.title('Testing Accuracy')\n    plt.legend()\n    \n    plt.figure(figsize=(15,5))\n    \n    # Comparing the Means over epochs\n    plt.subplot(121)\n    plt.plot(ap_mean, 'b', label='AP Mean')\n    plt.plot(an_mean, 'g', label='AN Mean')\n    plt.title('Means Comparision')\n    plt.legend()\n    \n    # Plotting the accuracy\n    ap_75quartile = (ap_mean+ap_stds)\n    an_75quartile = (an_mean-an_stds)\n    plt.subplot(122)\n    plt.plot(ap_75quartile, 'b', label='AP (Mean+SD)')\n    plt.plot(an_75quartile, 'g', label='AN (Mean-SD)')\n    plt.title('75th Quartile Comparision')\n    plt.legend()\n\ntest_metrics = np.array(test_metrics)\nplot_metrics(train_loss, test_metrics)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:07:24.345654Z","iopub.execute_input":"2022-01-21T17:07:24.345982Z","iopub.status.idle":"2022-01-21T17:07:24.956604Z","shell.execute_reply.started":"2022-01-21T17:07:24.34595Z","shell.execute_reply":"2022-01-21T17:07:24.95574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Using the Model**\n\nNow that we've finished training our model, we need to **extract the encoder** so that we can use it to encode images and then get use the feature vectors to compute the distance between those images.\n\nWe'll also be saving the encoder for latter use.","metadata":{}},{"cell_type":"code","source":"def extract_encoder(model):\n    encoder = get_encoder((128, 128, 3))\n    i=0\n    for e_layer in model.layers[0].layers[3].layers:\n        layer_weight = e_layer.get_weights()\n        encoder.layers[i].set_weights(layer_weight)\n        i+=1\n    return encoder\n\nencoder = extract_encoder(siamese_model)\nencoder.save_weights(\"encoder\")\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:07:45.265846Z","iopub.execute_input":"2022-01-21T17:07:45.26625Z","iopub.status.idle":"2022-01-21T17:07:47.277053Z","shell.execute_reply.started":"2022-01-21T17:07:45.266205Z","shell.execute_reply":"2022-01-21T17:07:47.276082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classify Images\n\nTo compute the distance between the encodings of the images, we'll be using distance formula. Distance over a certain threshold to be \"different\" and below the threshold as \"same\".","metadata":{}},{"cell_type":"code","source":"def classify_images(face_list1, face_list2, threshold=1.3):\n    # Getting the encodings for the passed faces\n    tensor1 = encoder.predict(face_list1)\n    tensor2 = encoder.predict(face_list2)\n    \n    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n    prediction = np.where(distance<=threshold, 0, 1)\n    return prediction","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:07:54.509617Z","iopub.execute_input":"2022-01-21T17:07:54.509945Z","iopub.status.idle":"2022-01-21T17:07:54.514983Z","shell.execute_reply.started":"2022-01-21T17:07:54.509914Z","shell.execute_reply":"2022-01-21T17:07:54.513887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ModelMetrics(pos_list, neg_list):\n    true = np.array([0]*len(pos_list)+[1]*len(neg_list))\n    pred = np.append(pos_list, neg_list)\n    \n    # Compute and print the accuracy\n    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n    \n    # Compute and plot the Confusion matrix\n    cf_matrix = confusion_matrix(true, pred)\n\n    categories  = ['Similar','Different']\n    names = ['True Similar','False Similar', 'False Different','True Different']\n    percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n\n    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n\n    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n                xticklabels = categories, yticklabels = categories)\n\n    plt.xlabel(\"Predicted\", fontdict = {'size':14}, labelpad = 10)\n    plt.ylabel(\"Actual\"   , fontdict = {'size':14}, labelpad = 10)\n    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n\n\npos_list = np.array([])\nneg_list = np.array([])\n\nfor data in get_batch(test_triplet, batch_size=256):\n    a, p, n = data\n    pos_list = np.append(pos_list, classify_images(a, p))\n    neg_list = np.append(neg_list, classify_images(a, n))\n    break\n\nModelMetrics(pos_list, neg_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:07:56.920407Z","iopub.execute_input":"2022-01-21T17:07:56.920736Z","iopub.status.idle":"2022-01-21T17:08:00.279165Z","shell.execute_reply.started":"2022-01-21T17:07:56.920707Z","shell.execute_reply":"2022-01-21T17:08:00.278267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n\n- FaceNet: A Unified Embedding for Face Recognition and Clustering: https://arxiv.org/abs/1503.03832\n- Image similarity estimation using a Siamese Network with a triplet loss: https://keras.io/examples/vision/siamese_network/\n- Celebrity Face Recognition: https://www.kaggle.com/ravehgillmore/celebrity-face-recognition/\n- Face Recognition using Siamese Networks: https://medium.com/wicds/face-recognition-using-siamese-networks-84d6f2e54ea4\n","metadata":{}}]}